#!/usr/bin/ruby1.9.3

# ##############################################################################
#
# Copyright (C) 2015 Opinsys Oy
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 2 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program. If not, see <http://www.gnu.org/licenses/>.
#
# ##############################################################################
#
# Managed images
#
# Images downloaded by this script, data stored under /var/lib/puavo/images.json
# Unmanaged images - other images
#
# By default the script handles only the managed images and unmanaged images
# are left untouched. The script can be asked to delete unmanaged images with 
# command line option --delete-unmanaged. When asked, the script will delete 
# all unknown files under /opt/ltsp/images and /opt/ltsp/images/rdiffs. Images 
# do not need to have .img ending.
#
# Operation
#
# Steps done by the script:
#
# 1. Check image series source URLs from device.json
# 2. Load image series description JSON files from specified URLs
# 3. Determine wanted full images oldest first and start syncing them one by one oldest first
# 4. Check if there is an old image available that has a diff to wanted target image
# 5. Download diffs needed by locally installed client devices
# 6. Delete old unused managed images + rdiffs
# 7. Delete unmanaged images if asked
#
# The managed images and rdiffs are stored under /var/lib/puavo/images.json. The 
# contents of the file are the same as the last loaded image series json file. 

require "digest"
require 'digest/sha2'
require 'fileutils'
require 'highline/import'
require 'json'
require 'net/http'
require 'puavo'
require 'puavo/etc'
require 'puavo/rest-client'
require 'rest-client'
require 'syslog'

def log(level, channel, priority, msg, color)
  logmsg = "%s %s" % [ logprefix(level), msg ]

  Syslog.log(priority, "%s", logmsg)

  outmsg = color  ?  HighLine.new.color(logmsg, color)  :  logmsg
  channel.puts(outmsg)
end

def logprefix(level)
  spacecount = [5, [5-level, 0].max ].min	# (5-level between [0,5])
  arrowcount = [0, [  level, 5].min ].max	# (  level between [0,5])
  return (" " * spacecount  +  ">" * arrowcount)
end

def debug(level, msg, color=nil)
  log(level, STDOUT, Syslog::LOG_DEBUG, msg, color)
end

def info(level, msg, color=nil)
  log(level, STDOUT, Syslog::LOG_INFO, msg, color)
end

def warning(level, msg)
  log(level, STDERR, Syslog::LOG_WARNING, msg, HighLine::RED)
end

class Series
  attr_reader :name

  def initialize(name)
    @name = name

    @by_id = Hash.new
    @by_version = Hash.new
  end

  def add_image(image)
    @by_id[image.id] = @by_version[image.version] = image
  end

  def get_by_id(id)
    return @by_id[id]
  end

  def get_by_version(version)
    return @by_version[version]
  end

  def mark_image_in_use(image_id)
    image = @by_id[image_id]
    if image
      image.mark_in_use
    end
  end

  def mark_diff_in_use(old_image_id, new_image_id)
    old_image = @by_id[old_image_id]
    new_image = @by_id[new_image_id]

    if old_image && new_image
      new_image.mark_diff_in_use(old_image)
    end
  end

  def add_diff(from_version, to_version, filename, size, sha256, urls)
    baseimage = get_by_version(from_version)
    targetimage = get_by_version(to_version)

    if baseimage && targetimage
      diff = Diff.new(baseimage, targetimage, filename, size, sha256, urls)
      targetimage.add_diff(diff)
    end
  end

  # Query puavo-rest for all devices and check used images.
  # Images and diffs are marked.
  def add_puavo_device_image_requests()
    client = PuavoRestClient.new :auth => :etc

    res = client.get("/v3/devices")
    devices = res.parse()

    devices.each do |device|
      bootmode             = device["boot_mode"]
      current_image        = device["current_image"]
      preferred_boot_image = device["preferred_boot_image"]
      preferred_image      = device["preferred_image"]

      mark_image_in_use(preferred_image)

      # Netboot devices do not need diffs, but want preferred boot images.
      if bootmode == "netboot"
        mark_image_in_use(preferred_boot_image)
        next
      end

      # Other devices need diffs from current image to preferred 
      if current_image && preferred_image && current_image != preferred_image
	mark_diff_in_use(current_image, preferred_image)
      end
    end
  end

  def images
    return @by_version.values
  end

  # Returns specified number of newest images in an array.  The images are
  # sorted oldest first so that when fetching the images, newer images can 
  # be created using diffs from older images.
  def newest_images(options)
    if options[:image]
      return Array( get_by_id(options[:image]) )
    end

    # Check which images and diffs are needed for non-netboot devices
    add_puavo_device_image_requests

    # We want to always download X number of newest images with Y number 
    # of diffs from newest images.
    newest_by_version(@by_version, options[:image_limit])
  end

  def sync(options)
    info(5, "Syncing series #{ @name } with the following images:")
    image_list = newest_images(options)
    image_list.each { |image| info(5, "  #{ image.id }") }

    FileUtils.mkdir_p(Image.basedir)
    FileUtils.mkdir_p(Diff.basedir)

    image_list.each do |image|
      info(4, "Starting sync for #{ image.id }")

      if image.materialize
        info(3, "Image sync OK: #{ image.statemsg }", HighLine::GREEN)
      else
        warning(3, "Image sync FAILED: #{ image.statemsg }")
      end

      if !options[:image]
        image.download_newest_diffs(options[:diff_limit])
      end
    end

    # No more interesting things to do if --image was given
    # (I guess we might not want to delete old stuff in this case).
    return if options[:image]

    info(4, "Downloading client diffs")

    images.each do |image|
      image.diffs.each do |diff|
        # we want only diffs that have been marked are in use
        next unless diff.in_use

        if diff.materialize
          info(3, "Diff sync OK: #{ diff.statemsg }", HighLine::GREEN)
        else
          warning(3, "Diff sync FAILED: #{ diff.statemsg }")
        end
      end
    end

    if !options[:keep_unused]
      # Delete all images and rdiffs that are not either newest
      # or used by some client.
      info(4, "Checking for old images and diffs to delete")

      images.each do |image|
        if !image.in_use
          image.delete	# does delete all diffs to image as well
          next
        end

        unused_diffs = image.diffs.select { |diff| !diff.in_use }
        unused_diffs.each do |diff|
          diff.delete
        end
      end
    end
  end

  def cleanup_tempfiles
    images.each { |image| image.cleanup_tempfiles }
  end
end

class SyncState
  StatesAndMessages = {
    :missing    => "%s is missing",
    :downloaded => "%s has been downloaded",
    :unverified => "%s is unverified",
    :inplace    => "%s is inplace",
    :deleted    => "%s has been deleted",
    :unknown    => "%s state is unknown",
  }

  def initialize()
    @state = :unknown
  end

  def message(filename)
    return (StatesAndMessages[@state] || StatesAndMessages[:unknown]) \
             % [ filename ]
  end

  def state=(new_state)
    raise "Unsupported state #{ new_state }" \
      unless StatesAndMessages.has_key?(new_state)

    @state = new_state
  end
end

class SyncFile
  attr_reader :filename, :in_use, :size

  def initialize(filename, sha256, size, urls)
    @filename = filename
    @sha256   = sha256
    @size     = size
    @urls     = urls

    @in_use        = false
    @mtime         = nil
    @state         = SyncState.new
    @verified      = false
    @verify_result = false
  end

  def delete
    all_possible_paths = [ download_path,
                           partial_unverified_path,
                           unverified_path,
                           final_path ]
    delete_files(all_possible_paths)
    @state.state = :deleted
  end

  def delete_files(filelist)
    filelist.each do |path|
      next unless File.exists?(path)
      infolevel = (path == final_path) ? 3 : 2
      info(infolevel, "Deleting #{ path }")
      begin
        File.delete(path)
      rescue StandardError => e
        warning(2, "Could not delete #{ path }: #{ e.message }")
      end
    end
  end

  def download
    @state.state = :missing

    # go through all @urls in order and try to download from each in turn
    # (we could also do some load balancing by first choosing one randomly?)
    @urls.each do |url|
      download_from_url(url) and return true
    end

    return false
  end

  # Download file from specified url and check that the sha256 checksum of 
  # the downloaded file matches the given size and sha256.
  # If the file was downloaded successfully and the size and the checksum
  # matches, true is returned, otherwise false is returned.
  # Development idea: it might be nice if this could support partial downloads
  # (append to an existing file).
  def download_from_url(url)
    uri = URI.parse(url)

    http = Net::HTTP.new(uri.host, uri.port)
    http.ca_file = "/etc/puavo/certs/rootca.pem"
  #  http.ca_file = "/etc/ssl/certs/SecureTrust_CA.pem" # XXX ?
    http.verify_mode = OpenSSL::SSL::VERIFY_PEER
    http.use_ssl = true

    http.request_get(uri.path) do |response|
      case response
      when Net::HTTPNotFound
        warning(2, "404 - Not Found (#{url})")
        return false

      when Net::HTTPOK
        hash = Digest::SHA2.new
        received_size = 0

        info(2, "Starting download from #{ url } to #{ download_path }")

        File.open(download_path, "w") do |temp_file|
          temp_file.binmode

          progress = 0
          total = response.header["Content-Length"].to_i

          response.read_body do |chunk|
            hash      << chunk
            temp_file << chunk

            received_size += chunk.size
            new_progress = (received_size * 100) / total
            if progress != new_progress
              progress = new_progress
              debug(1, "Downloading %s (%3d%%)" % [url, progress])
            end
          end
        end

        return false unless received_size == @size

        @state.state = :downloaded

        if hash.to_s != @sha256
          warning(2, "Checksum mismatch for #{ download_path }" \
                       + " (calculated while downloading)," \
                       + " expected #{ @sha256 }, received #{ hash.to_s }")
          File.delete(download_path)
          info(2, "Deleted #{ download_path }")
          return false
        end

        info(2, "Checksum verified for #{ download_path }" \
                  + " (calculated while downloading)")
        File.rename(download_path, final_path)
        info(2, "Moved #{ download_path } to #{ final_path }")
        @state.state = :inplace
        return true
      else
        warning(2, "puavo-rest-client error, received response" \
                     + " #{response.code}")
        return false
      end
    end

    return false
  end

  def do_path_cleanup(path)
    # The point of this is to check that filename does not get out of
    # basedir by having ".." or some such, it must be under basedir
    # (where the meaning of basedir is different for images and diffs).
    cleaned_up_path = File.expand_path(path)
    return cleaned_up_path if path.start_with?(self.class.basedir)

    raise "Invalid filename #{ path }"
  end

  def download_path
    return do_path_cleanup("#{ final_path }.partial")
  end

  def final_path
    return do_path_cleanup("#{ self.class.basedir }/#{ @filename }")
  end

  def partial_unverified_path
    return do_path_cleanup("#{ unverified_path }.partial")
  end

  def unverified_path
    return do_path_cleanup("#{ final_path }.unverified")
  end

  def inplace?
    return File.exists?(final_path)
  end

  def mark_in_use
    @in_use = true
  end

  def statemsg
    return @state.message(@filename)
  end

  # Checks if the file in the filesystem has the same sha256 as the metadata.
  # To speed up things, the filesize needs to match before sha256 is 
  # calculated. The results are cached and rechecked only if file mtime 
  # changes.
  def verify
    # We can speed things up by assuming that all files in proper place have
    # been verified before (but if $options[:force_verify] is true we will
    # verify anyway).
    if inplace?
      @state.state = :inplace
      return true unless $options[:force_verify]
      path_to_verify = final_path
    else
      path_to_verify = unverified_path
    end

    begin
      current_mtime = File.mtime(path_to_verify)
      current_size  = File.size(path_to_verify)
    rescue StandardError => e
      warning(2, "Problem in inspecting #{ path_to_verify }:" \
                   + " #{ e.message }")                       \
        unless e.kind_of?(Errno::ENOENT)
      @state.state = :unverified
      return @verified = @verify_result = false
    end

    if @verified && @mtime && @mtime == current_mtime
      return @verify_result
    end

    info(2, "Verifying #{ path_to_verify }")

    @verify_result = false
    @state.state = :unverified

    if current_size == @size
      @mtime = current_mtime
      digest = Digest::SHA2.file(path_to_verify).hexdigest
      @verify_result = (digest == @sha256)
      if @verify_result
        info(2, "Checksum verified for #{ path_to_verify }")
        if path_to_verify != final_path
          File.rename(path_to_verify, final_path)
          info(2, "Moved #{ path_to_verify } to #{ final_path }")
        end
        @state.state = :inplace
      else
        warning(2, "Checksum mismatch for #{ path_to_verify }, " \
                     + " expected #{ @sha256 }, received #{ digest }")
        if path_to_verify == unverified_path
          File.delete(path_to_verify)
          info(2, "Deleted #{ path_to_verify }")
        else
          # Do not delete in case the file is in final_path... even though
          # the file is probably broken, it is probably better to leave it
          # and try to patch/download a new one in its place.
        end
      end
    end

    @verified = true

    return @verify_result
  end

  def cleanup_tempfiles
    tempfiles_to_delete = [ download_path, partial_unverified_path ]
    tempfiles_to_delete << unverified_path if inplace?

    delete_files(tempfiles_to_delete)
  end
end

class Image < SyncFile
  attr_reader :id, :version

  def initialize(version, filename, size, sha256, id, urls)
    super(filename, sha256, size, urls)

    @version = version
    @diffs_from_by_version = Hash.new

    if id
      @id = id
    elsif /\A(.*)\.img\z/.match(filename)
      @id = $1
    else
      raise "Could not determine id for #{ filename }"
    end
  end

  def self.basedir; $options[:download_path]; end

  def mark_diff_in_use(from_image)
    diff = @diffs_from_by_version[from_image.version]
    if diff
      diff.mark_in_use
    end
  end

  def add_diff(diff)
    return unless diff.targetimage.version == @version

    if diff.baseimage.version != @version
      @diffs_from_by_version[diff.baseimage.version] = diff
    end
  end

  def diffs
    @diffs_from_by_version.values
  end

  def download_newest_diffs(limit=0)
    newest_by_version(@diffs_from_by_version, limit).each do |diff|
      diff.materialize
    end
  end

  def materialize
    mark_in_use

    verify         and return true
    patch_from_old and return true
    download       and return true

    return false
  end

  # Create the current image from an old image by using a patch. First 
  # all the possible diffs are sorted by size and the list is scanned twice:
  # first to check if there is an existing baseimage that has a patch 
  # available and if none is found, then the smallest sized diff for an 
  # existing baseimage is downloaded.
  def patch_from_old
    mindiffs = diffs.sort_by { |diff| diff.size }

    apply_diffs = lambda do |download_wanted|
                    mindiffs.each do |diff|
                      diff.apply(download_wanted) \
                        and verify                \
                        and return true
                    end
                    return false
                  end

    info(3, "Trying to patch a new image from existing images and diffs")
    apply_diffs.call(false) and return true
    info(3, "Trying to patch a new image by downloading rdiffs and patching")
    apply_diffs.call(true)  and return true

    info(3, "(Did not succeed in patching from an old image)")
    return false
  end

  def delete
    diffs.each { |diff| diff.delete }
    super
  end

  def cleanup_tempfiles
    diffs.each { |diff| diff.cleanup_tempfiles }
    super
  end
end

class Diff < SyncFile
  attr_reader :baseimage, :targetimage

  def initialize(baseimage, targetimage, filename, size, sha256, urls)
    super(filename, sha256, size, urls)

    @baseimage   = baseimage
    @targetimage = targetimage
  end

  def self.basedir; "#{ $options[:download_path] }/rdiffs"; end

  def do_patching
    source      = @baseimage.final_path
    target      = @targetimage.unverified_path
    temp_target = @targetimage.partial_unverified_path

    info(2, "Starting patching from #{ source } to #{ temp_target }")

    if !system("rdiff", "patch", source, final_path, temp_target)
      warning(2, "rdiff failed with exit code: #{ $?.exitstatus }" \
                   + "  when using #{ final_path }")
      return false      
    end

    info(3, "Patched #{ temp_target } successfully")

    File.rename(temp_target, target)

    info(2, "Moved #{ temp_target } to #{ target }")

    return true
  end

  def apply(download_wanted)
    @baseimage.verify                               \
      and ((download_wanted or verify) or download) \
      and do_patching                               \
      and return true

    return false
  end

  def materialize
    mark_in_use

    verify   and return true
    download and return true

    return false
  end
end

def get_all_series(options)
  # Load series information from various sources: lookup --url parameters
  # first, and if those are not given, lookup sources specified in bootserver
  # information in Puavo.  Check out --file parameters as well (if some series
  # is defined in --file parameters, these will override previous ones).
  all_series_list = []

  series_urls = options[:url]
  if series_urls.empty? && !options[:no_puavo_series_url_lookup]
    series_urls = fetch_series_urls()
  end
  series_urls.each do |series_url|
    all_series_list << fetch_and_parse_series_data(series_url)
  end

  options[:file].each do |series_file|
    info(5, "Using file #{ series_file }")
    all_series_list << parse_series_data( JSON.parse( IO.read(series_file) ) )
  end

  all_series = all_series_list.reduce(&:merge)

  if options[:series]
    series_name = options[:series]
    if all_series[series_name]
      info(5, "Using only series #{series_name}")
      return [ all_series[series_name] ]
    end

    raise "No series named #{ series_name } found" \
            + " (given as --series parameter)"
  end

  if all_series.empty?
    raise "No series information, can not do anything"
  end

  return all_series.values
end

def newest_by_version(collection_by_version, limit)
  versions = collection_by_version.keys.sort.reverse.slice(0,limit).reverse
  return versions.map { |version| collection_by_version[version] }
end

def parse_series_data(series_data)
  result = Hash.new

  series_data.each_pair do |series_name, data|
    series = Series.new(series_name)

    data["images"].each do |image|
      image = Image.new(image["version"],
                        image["filename"],
                        image["size"],
                        image["sha256"],
                        image["id"],
                        [ image["url"] ])
      series.add_image(image)
    end

    data["images"].each do |image|
      if image["diffs"]
        image["diffs"].each do |data|
          series.add_diff(data["version"],
                          image["version"],
                          data["filename"],
                          data["size"],
                          data["sha256"],
                          [ data["url"] ])
        end
      end
    end

    result[series_name] = series
  end

  result
end

#
def fetch_source_urls
  etc = PuavoEtc.new
  client = PuavoRestClient.new :auth => :etc

  url = "/v3/boot_servers/#{ etc.hostname }"

  info(5, "Loading bootserver data from puavo-rest url: #{ url }")
  res = client.get(url)
  data = res.parse()

  source_urls = data["image_series_sources"]

  raise 'Could not read sources urls from Puavo' \
    unless source_urls.kind_of?(Array)

  return source_urls
end

# Load series json definition files 
def fetch_and_parse_series_data(source_url)
  info(5, "Using image series source url #{ source_url }")

  uri = URI.parse(source_url)

  http = Net::HTTP.new(uri.host, uri.port)
  http.ca_file = "/etc/puavo/certs/rootca.pem"
  http.verify_mode = OpenSSL::SSL::VERIFY_PEER
  http.use_ssl = true

  series_by_name = {}
  http.request_get(uri.path) do |response|
    series_by_name = parse_series_data( JSON.parse( response.body ) )
  end

  return series_by_name
end

script_name = File.basename(__FILE__)

Syslog.open(script_name, Syslog::LOG_CONS)

$options = Hash.new

parser = OptionParser.new do |opts|
  opts.banner = <<BANNER_EOF
  Image sync tool for bootservers to download client images from image server.
  This tool touches only files that have .img or rdiff ending.

  Image series is a collection of images that are based on same underlying
  system.  They are versioned and updates from older to newer versions are
  supported.

  Images are downloaded from an image server. The series is defined by a JSON
  file that contains information about images and diffs.  The image source
  URL is defined in bootserver settings in Puavo and the script queries the
  information from puavo-rest by default.  Series information is parsed from
  the JSON files and by default the following images and diffs are downloaded:

  * Newest image from each series
  * Diffs from 2nd and 3rd newest image in the series
  * All images used by netboot devices
  * All preferred images used by non-netboot devices
  * All diffs needed by non-netboot devices to update from the current image
    to preferred images

  All files have checksums that are checked before they are actually used.
  
  An example that defines two images and a diff between them:

{
  "demo-trusty": {
    "images": [
      {
        "size": 10146996224,
        "sha256": "24e2f84a89a0b0126e0cfd457fe016016181e82f9e49d437fd465de69525b271",
        "url": "https://imageserver.puavo.org/demo-trusty-2015-03-25-104000-i386.img",
        "filename": "demo-trusty-2015-03-25-104000-i386.img",
        "id": "demo-trusty-2015-03-25-104000-i386",
        "version": 20150325104000
      },
      {
        "diffs": [
          {
            "url": "https://imageserver.puavo.org/rdiffs/demo-trusty-2015-03-25-104000--2015-04-10-103142-i386.rdiff",
            "sha256": "f00a308de2ad01e0a27507412faca5faed288318a225f40d4cd261b647f689fb",
            "size": 735394218,
            "version": 20150325104000,
            "filename": "demo-trusty-2015-03-25-104000--2015-04-10-103142-i386.rdiff"
          },
        ],
        "size": 10213441536,
        "sha256": "432cb4055664d0c1dc3d9e6a58833ef7939dd5af24d9af2e47f6607ea88f5c60",
        "url": "https://imageserver.puavo.org/demo-trusty-2015-04-10-103142-i386.img",
        "filename": "demo-trusty-2015-04-10-103142-i386.img",
        "id": "demo-trusty-2015-04-10-103142-i386",
        "version": 20150410103142
      },
    ]
  }
}


  Usage: #{script_name} [options]

  Options:
BANNER_EOF

  $options[:keep_unused] = false
  opts.on("--keep-unused",
          "Do no delete images that are not currently used by any client.") do
    $options[:keep_unused] = true
  end

  $options[:file] = []
  opts.on("--file PATH", "JSON series information file to read") do |file|
    $options[:file] << file
  end

  $options[:url] = []
  opts.on("--url URL", "Source URL to load JSON series information") do |url|
    $options[:url] << url
  end

  $options[:force_verify] = false
  opts.on("--force-verify", "Force verification of each image/rdiff") do
    $options[:force_verify] = true
  end

  $options[:image_limit] = 2
  opts.on("--image-limit NUMBER", "Number of newest images to sync from all specified series (Default: 2)") do |limit|
    $options[:image_limit] = limit
  end

  $options[:diff_limit] = 2
  opts.on("--diff-limit NUMBER", "Number of newest diffs to sync for synced images even if there are no clients using them. (Default: 2)") do |limit|
    $options[:diff_limit] = limit
  end

  $options[:download_path] = "/opt/ltsp/images"
  opts.on("--download-path PATH") do |path|
    $options[:download_path] = path
  end

  $options[:no_puavo_series_url_lookup] = false
  opts.on("--no-puavo-series-url-lookup",
          "Do not lookup series URLs from Puavo") do
    $options[:no_puavo_series_url_lookup] = true
  end

  $options[:series] = nil
  opts.on("--series NAME", "Download only specified series instead of all series specified by the sources.") do |series|
    $options[:series] = series
  end

  $options[:image] = nil
  opts.on("--image NAME", "Sync only the specified image") do |image|
    $options[:image] = image
  end

  opts.on_tail("-h", "--help", "Show this message") do
    STDERR.puts opts
    exit
  end
end

parser.parse!

begin
  all_series = get_all_series($options)

  info(5, "Cleaning up temporary files")
  all_series.each do |series|
    series.cleanup_tempfiles
  end

  all_series.each do |series|
    series.sync($options)
  end

rescue StandardError => e
  warning(5, "Error: #{ e.message }")
  raise e
end

Syslog.close()

exit 0
